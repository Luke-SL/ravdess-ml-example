{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≠ Classifica√ß√£o de Emo√ß√µes a partir de √Åudio\n",
    "\n",
    "## Apresenta√ß√£o - Machine Learning para An√°lise Emocional\n",
    "\n",
    "**Objetivo:** Criar um modelo que identifica emo√ß√µes (feliz, triste, raiva, neutro) a partir de caracter√≠sticas ac√∫sticas da voz.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Instala√ß√£o e Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar bibliotecas necess√°rias (executar uma vez)\n",
    "# !pip install librosa scikit-learn matplotlib seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Configura√ß√£o para gr√°ficos mais bonitos\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéµ 2. Como as Emo√ß√µes Afetam a Voz?\n",
    "\n",
    "Diferentes emo√ß√µes produzem padr√µes ac√∫sticos distintos:\n",
    "\n",
    "| Emo√ß√£o | Pitch | Intensidade | Taxa de Fala | Caracter√≠sticas |\n",
    "|--------|-------|-------------|--------------|------------------|\n",
    "| **Feliz** | Alto | M√©dia-Alta | R√°pida | Entona√ß√£o variada |\n",
    "| **Triste** | Baixo | Baixa | Lenta | Entona√ß√£o mon√≥tona |\n",
    "| **Raiva** | Alto | Alta | R√°pida | Energia concentrada |\n",
    "| **Neutro** | M√©dio | M√©dia | M√©dia | Padr√£o equilibrado |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 3. Extra√ß√£o de Features (Caracter√≠sticas)\n",
    "\n",
    "Vamos extrair **features ac√∫sticas** que capturam essas diferen√ßas:\n",
    "\n",
    "1. **MFCCs** - Mel-Frequency Cepstral Coefficients (textura do som)\n",
    "2. **Pitch** - Frequ√™ncia fundamental (tom da voz)\n",
    "3. **Energia (RMS)** - Intensidade do sinal\n",
    "4. **Zero Crossing Rate** - Taxa de mudan√ßa de sinal\n",
    "5. **Spectral Contrast** - Diferen√ßa entre picos e vales do espectro\n",
    "6. **Chroma** - Informa√ß√£o tonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, duration=3):\n",
    "    \"\"\"\n",
    "    Extrai features ac√∫sticas de um arquivo de √°udio\n",
    "    \n",
    "    Retorna: array com ~50 features\n",
    "    \"\"\"\n",
    "    # Carregar √°udio\n",
    "    y, sr = librosa.load(audio_path, duration=duration, sr=22050)\n",
    "    \n",
    "    # 1. MFCCs (13 coeficientes)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_std = np.std(mfccs, axis=1)\n",
    "    \n",
    "    # 2. Chroma (12 valores)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "    chroma_std = np.std(chroma, axis=1)\n",
    "    \n",
    "    # 3. Spectral Contrast (7 bandas)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    contrast_mean = np.mean(contrast, axis=1)\n",
    "    \n",
    "    # 4. Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    zcr_std = np.std(zcr)\n",
    "    \n",
    "    # 5. RMS Energy\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    rms_mean = np.mean(rms)\n",
    "    rms_std = np.std(rms)\n",
    "    \n",
    "    # 6. Pitch\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch_mean = np.mean(pitches[pitches > 0]) if len(pitches[pitches > 0]) > 0 else 0\n",
    "    \n",
    "    # Concatenar todas as features\n",
    "    features = np.concatenate([\n",
    "        mfccs_mean, mfccs_std,      # 26 features\n",
    "        chroma_mean, chroma_std,     # 24 features\n",
    "        contrast_mean,               # 7 features\n",
    "        [zcr_mean, zcr_std, rms_mean, rms_std, pitch_mean]  # 5 features\n",
    "    ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(f\"‚úÖ Fun√ß√£o de extra√ß√£o criada! Retorna {13*2 + 12*2 + 7 + 5} features por √°udio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä 4. Visualiza√ß√£o de Features de √Åudio\n",
    "\n",
    "Vamos ver como o √°udio √© processado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(audio_path, title=\"An√°lise de √Åudio\"):\n",
    "    \"\"\"\n",
    "    Visualiza as principais caracter√≠sticas de um √°udio\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, duration=3)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Forma de onda\n",
    "    axes[0, 0].plot(np.linspace(0, len(y)/sr, len(y)), y)\n",
    "    axes[0, 0].set_title('Forma de Onda', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Tempo (s)')\n",
    "    axes[0, 0].set_ylabel('Amplitude')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Espectrograma\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', \n",
    "                                   ax=axes[0, 1], cmap='viridis')\n",
    "    axes[0, 1].set_title('Espectrograma', fontweight='bold')\n",
    "    fig.colorbar(img, ax=axes[0, 1], format='%+2.0f dB')\n",
    "    \n",
    "    # 3. MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    img2 = librosa.display.specshow(mfccs, sr=sr, x_axis='time', \n",
    "                                    ax=axes[1, 0], cmap='coolwarm')\n",
    "    axes[1, 0].set_title('MFCCs', fontweight='bold')\n",
    "    fig.colorbar(img2, ax=axes[1, 0])\n",
    "    \n",
    "    # 4. Energia RMS\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    times = librosa.frames_to_time(range(len(rms)), sr=sr)\n",
    "    axes[1, 1].plot(times, rms, linewidth=2, color='purple')\n",
    "    axes[1, 1].set_title('Energia RMS', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Tempo (s)')\n",
    "    axes[1, 1].set_ylabel('Energia')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de visualiza√ß√£o criada!\")\n",
    "print(\"   Use: visualize_audio('seu_audio.wav', 'Meu √Åudio')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ 5. Cria√ß√£o do Modelo de Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier:\n",
    "    \"\"\"\n",
    "    Classificador de Emo√ß√µes\n",
    "    \n",
    "    Modelos dispon√≠veis:\n",
    "    - 'svm': Support Vector Machine (melhor para dados pequenos)\n",
    "    - 'rf': Random Forest (mais interpret√°vel)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_type='svm'):\n",
    "        self.model_type = model_type\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        if model_type == 'svm':\n",
    "            self.model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "        elif model_type == 'rf':\n",
    "            self.model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"Treina o modelo\"\"\"\n",
    "        # Normalizar features (importante para SVM)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        # Treinar\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        print(f\"‚úÖ Modelo {self.model_type.upper()} treinado!\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Faz predi√ß√µes\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Retorna probabilidades\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Avalia o modelo\"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"ACUR√ÅCIA: {accuracy:.2%}\")\n",
    "        print(\"=\"*50)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "print(\"‚úÖ Classe EmotionClassifier criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ 6. Prepara√ß√£o dos Dados\n",
    "\n",
    "### Como usar com seus pr√≥prios dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXEMPLO COM DADOS REAIS (descomente quando tiver seus arquivos)\n",
    "\"\"\"\n",
    "# Estrutura de pastas recomendada:\n",
    "# data/\n",
    "#   ‚îú‚îÄ‚îÄ feliz/\n",
    "#   ‚îÇ   ‚îú‚îÄ‚îÄ audio1.wav\n",
    "#   ‚îÇ   ‚îî‚îÄ‚îÄ audio2.wav\n",
    "#   ‚îú‚îÄ‚îÄ triste/\n",
    "#   ‚îú‚îÄ‚îÄ raiva/\n",
    "#   ‚îî‚îÄ‚îÄ neutro/\n",
    "\n",
    "import os\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    \n",
    "    for emotion in ['feliz', 'triste', 'raiva', 'neutro']:\n",
    "        emotion_dir = os.path.join(data_dir, emotion)\n",
    "        for filename in os.listdir(emotion_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                audio_files.append(os.path.join(emotion_dir, filename))\n",
    "                labels.append(emotion)\n",
    "    \n",
    "    return audio_files, labels\n",
    "\n",
    "# Carregar dados\n",
    "audio_files, labels = load_dataset('data/')\n",
    "\n",
    "# Extrair features\n",
    "X = []\n",
    "y = []\n",
    "for audio, label in zip(audio_files, labels):\n",
    "    try:\n",
    "        features = extract_features(audio)\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    except:\n",
    "        print(f\"Erro ao processar {audio}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù C√≥digo exemplo preparado!\")\n",
    "print(\"   Para usar com dados reais, descomente o c√≥digo acima.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ 7. Demonstra√ß√£o com Dados Sint√©ticos\n",
    "\n",
    "Para fins de demonstra√ß√£o, vamos simular dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados sint√©ticos para demonstra√ß√£o\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 200  # 50 de cada emo√ß√£o\n",
    "n_features = 62  # total de features extra√≠das\n",
    "\n",
    "# Simular padr√µes diferentes para cada emo√ß√£o\n",
    "X_feliz = np.random.randn(n_samples//4, n_features) + 0.5\n",
    "X_triste = np.random.randn(n_samples//4, n_features) - 0.5\n",
    "X_raiva = np.random.randn(n_samples//4, n_features) + 1.0\n",
    "X_neutro = np.random.randn(n_samples//4, n_features)\n",
    "\n",
    "# Combinar\n",
    "X = np.vstack([X_feliz, X_triste, X_raiva, X_neutro])\n",
    "y = np.array(['feliz']*50 + ['triste']*50 + ['raiva']*50 + ['neutro']*50)\n",
    "\n",
    "print(f\"‚úÖ Dataset sint√©tico criado!\")\n",
    "print(f\"   Total de amostras: {len(X)}\")\n",
    "print(f\"   Features por amostra: {X.shape[1]}\")\n",
    "print(f\"   Distribui√ß√£o: {dict(zip(*np.unique(y, return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÄ 8. Dividir em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados: 80% treino, 20% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # manter propor√ß√£o de classes\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dados divididos!\")\n",
    "print(f\"   Treino: {len(X_train)} amostras\")\n",
    "print(f\"   Teste: {len(X_test)} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è 9. Treinar os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: SVM\n",
    "print(\"Treinando SVM...\")\n",
    "clf_svm = EmotionClassifier(model_type='svm')\n",
    "clf_svm.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Random Forest\n",
    "print(\"Treinando Random Forest...\")\n",
    "clf_rf = EmotionClassifier(model_type='rf')\n",
    "clf_rf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà 10. Avaliar os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar SVM\n",
    "print(\"\\nüîç AVALIA√á√ÉO - SVM\")\n",
    "y_pred_svm = clf_svm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar Random Forest\n",
    "print(\"\\nüîç AVALIA√á√ÉO - RANDOM FOREST\")\n",
    "y_pred_rf = clf_rf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä 11. Matriz de Confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confus√£o para o melhor modelo (SVM)\n",
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "emotions = sorted(np.unique(y))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotions, yticklabels=emotions,\n",
    "            cbar_kws={'label': 'Contagem'})\n",
    "plt.title('Matriz de Confus√£o - SVM', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Emo√ß√£o Real', fontsize=12)\n",
    "plt.xlabel('Emo√ß√£o Predita', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé§ 12. Fazer Predi√ß√£o em Novo √Åudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(classifier, audio_path):\n",
    "    \"\"\"\n",
    "    Prediz emo√ß√£o de um novo √°udio\n",
    "    \"\"\"\n",
    "    # Extrair features\n",
    "    features = extract_features(audio_path).reshape(1, -1)\n",
    "    \n",
    "    # Predi√ß√£o\n",
    "    emotion = classifier.predict(features)[0]\n",
    "    probabilities = classifier.predict_proba(features)[0]\n",
    "    \n",
    "    # Visualizar\n",
    "    emotions = sorted(np.unique(y_train))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#FF6B6B' if e == emotion else '#4ECDC4' for e in emotions]\n",
    "    bars = plt.bar(emotions, probabilities, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    plt.title(f'Predi√ß√£o de Emo√ß√£o\\nResultado: {emotion.upper()}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Probabilidade', fontsize=12)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Adicionar valores\n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{prob:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return emotion, probabilities\n",
    "\n",
    "# Exemplo de uso (descomente quando tiver um √°udio real):\n",
    "# emotion, probs = predict_emotion(clf_svm, 'meu_audio.wav')\n",
    "# print(f\"\\nüéØ Emo√ß√£o detectada: {emotion}\")\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de predi√ß√£o criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé® 13. Visualizar Exemplo de Predi√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√£o em uma amostra de teste\n",
    "sample_idx = 0\n",
    "sample_features = X_test[sample_idx:sample_idx+1]\n",
    "true_emotion = y_test[sample_idx]\n",
    "\n",
    "predicted_emotion = clf_svm.predict(sample_features)[0]\n",
    "probabilities = clf_svm.predict_proba(sample_features)[0]\n",
    "emotions = sorted(np.unique(y))\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#FF6B6B' if e == predicted_emotion else '#4ECDC4' for e in emotions]\n",
    "bars = plt.bar(emotions, probabilities, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "plt.title(f'Exemplo de Predi√ß√£o\\nReal: {true_emotion} | Predito: {predicted_emotion}', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Probabilidade', fontsize=12)\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, prob in zip(bars, probabilities):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{prob:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ 14. Pr√≥ximos Passos\n",
    "\n",
    "Para melhorar o modelo:\n",
    "\n",
    "1. **Mais Dados**\n",
    "   - Usar datasets p√∫blicos: RAVDESS, TESS, CREMA-D\n",
    "   - Gravar seus pr√≥prios √°udios\n",
    "\n",
    "2. **Deep Learning**\n",
    "   - CNNs para processar espectrogramas\n",
    "   - RNNs/LSTMs para capturar temporalidade\n",
    "   - Transfer learning com modelos pr√©-treinados\n",
    "\n",
    "3. **Features Avan√ßadas**\n",
    "   - Formantes\n",
    "   - Jitter e Shimmer\n",
    "   - An√°lise pros√≥dica\n",
    "\n",
    "4. **Otimiza√ß√£o**\n",
    "   - Grid search para hiperpar√¢metros\n",
    "   - Cross-validation\n",
    "   - Ensemble de modelos\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Datasets Recomendados\n",
    "\n",
    "- **RAVDESS**: Ryerson Audio-Visual Database of Emotional Speech\n",
    "- **TESS**: Toronto Emotional Speech Set\n",
    "- **CREMA-D**: Crowd-sourced Emotional Multimodal Actors Dataset\n",
    "- **SAVEE**: Surrey Audio-Visual Expressed Emotion\n",
    "- **EMO-DB**: Berlin Database of Emotional Speech\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclus√£o\n",
    "\n",
    "Criamos um classificador de emo√ß√µes completo:\n",
    "- ‚úÖ Extra√ß√£o de features ac√∫sticas\n",
    "- ‚úÖ Treinamento de modelos ML\n",
    "- ‚úÖ Avalia√ß√£o e visualiza√ß√£o\n",
    "- ‚úÖ Predi√ß√£o em novos √°udios\n",
    "\n",
    "**Acur√°cia t√≠pica com dados reais:** 60-80%\n",
    "\n",
    "---\n",
    "\n",
    "### üë®‚Äçüíª C√≥digo dispon√≠vel para uso em sua apresenta√ß√£o!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
