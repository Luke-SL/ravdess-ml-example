# ğŸ­ Classificador de EmoÃ§Ãµes de Ãudio - Material para ApresentaÃ§Ã£o

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Notebook Jupyter (Recomendado para ApresentaÃ§Ã£o)

O notebook Ã© ideal para apresentaÃ§Ãµes interativas:

```bash
# 1. Instalar Jupyter
pip install jupyter

# 2. Abrir o notebook
jupyter notebook emotion_classifier_notebook.ipynb
```

O notebook contÃ©m:
- âœ… ExplicaÃ§Ãµes didÃ¡ticas
- âœ… CÃ³digo comentado
- âœ… VisualizaÃ§Ãµes
- âœ… Exemplo completo passo a passo

### OpÃ§Ã£o 2: Script Python

Para execuÃ§Ã£o direta:

```bash
# 1. Instalar dependÃªncias
pip install librosa scikit-learn matplotlib seaborn numpy

# 2. Executar
python emotion_classifier.py
```

---

## ğŸ“Š O Que o Algoritmo Faz?

### Pipeline de ClassificaÃ§Ã£o:

```
ÃUDIO (.wav) 
    â†“
PRÃ‰-PROCESSAMENTO
    â†“
EXTRAÃ‡ÃƒO DE FEATURES
  â€¢ MFCCs (textura do som)
  â€¢ Pitch (tom da voz)
  â€¢ Energia RMS (intensidade)
  â€¢ Zero Crossing Rate
  â€¢ Spectral Contrast
  â€¢ Chroma (informaÃ§Ã£o tonal)
    â†“
NORMALIZAÃ‡ÃƒO
    â†“
MODELO ML (SVM/Random Forest)
    â†“
PREDIÃ‡ÃƒO: feliz/triste/raiva/neutro
```

---

## ğŸ¯ Features ExtraÃ­das

O algoritmo extrai **62 features** de cada Ã¡udio:

| Feature | Quantidade | O que representa |
|---------|-----------|------------------|
| MFCCs | 26 | Envelope espectral (textura) |
| Chroma | 24 | InformaÃ§Ã£o tonal |
| Spectral Contrast | 7 | DiferenÃ§a picos/vales |
| Zero Crossing Rate | 2 | Taxa de mudanÃ§a de sinal |
| RMS Energy | 2 | Intensidade do som |
| Pitch | 1 | FrequÃªncia fundamental |

---

## ğŸ¤– Modelos Implementados

### 1. SVM (Support Vector Machine)
- âœ… Melhor para datasets pequenos
- âœ… Boa generalizaÃ§Ã£o
- âš™ï¸ Kernel RBF

### 2. Random Forest
- âœ… Mais interpretÃ¡vel
- âœ… Fornece importÃ¢ncia de features
- âš™ï¸ 100 Ã¡rvores

---

## ğŸ“ˆ Resultados Esperados

Com dados **reais** e bem balanceados:
- ğŸ¯ **AcurÃ¡cia tÃ­pica:** 60-80%
- ğŸ“Š **Melhores emoÃ§Ãµes:** raiva e feliz (mais distintas)
- ğŸ”„ **ConfusÃ£o comum:** neutro vs. triste

Com os **dados sintÃ©ticos** da demo:
- ğŸ¯ **AcurÃ¡cia:** ~80% (SVM)

---

## ğŸ—‚ï¸ Como Usar com Seus Dados

### Estrutura de DiretÃ³rios:

```
seu_projeto/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ feliz/
â”‚   â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”‚   â”œâ”€â”€ audio2.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ triste/
â”‚   â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ raiva/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ neutro/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ emotion_classifier.py
â””â”€â”€ emotion_classifier_notebook.ipynb
```

### CÃ³digo para Carregar Dados:

```python
import os

# Carregar arquivos
audio_files = []
labels = []

for emotion in ['feliz', 'triste', 'raiva', 'neutro']:
    emotion_dir = f'data/{emotion}'
    for filename in os.listdir(emotion_dir):
        if filename.endswith('.wav'):
            audio_files.append(os.path.join(emotion_dir, filename))
            labels.append(emotion)

# Extrair features
X, y = prepare_dataset(audio_files, labels)

# Treinar
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
classifier = EmotionClassifier(model_type='svm')
classifier.train(X_train, y_train)
```

---

## ğŸ“š Datasets Recomendados

Para treinar com dados reais, use estes datasets pÃºblicos:

1. **RAVDESS** (Ryerson Audio-Visual Database)
   - 7.356 arquivos
   - 24 atores
   - 8 emoÃ§Ãµes
   - Download: https://zenodo.org/record/1188976

2. **TESS** (Toronto Emotional Speech Set)
   - 2.800 arquivos
   - 2 atrizes
   - 7 emoÃ§Ãµes
   - Download: https://tspace.library.utoronto.ca/handle/1807/24487

3. **CREMA-D**
   - 7.442 arquivos
   - 91 atores
   - 6 emoÃ§Ãµes
   - Download: https://github.com/CheyneyComputerScience/CREMA-D

---

## ğŸ¨ VisualizaÃ§Ãµes IncluÃ­das

### 1. Matriz de ConfusÃ£o
Mostra onde o modelo acerta e erra:
- Diagonal principal = acertos
- Fora da diagonal = confusÃµes

### 2. Probabilidades de EmoÃ§Ã£o
Para cada prediÃ§Ã£o, mostra:
- ConfianÃ§a em cada classe
- EmoÃ§Ã£o vencedora destacada

### 3. Pipeline Diagram
VisualizaÃ§Ã£o completa do fluxo de processamento

---

## ğŸ”§ DependÃªncias

```
librosa>=0.10.0      # Processamento de Ã¡udio
scikit-learn>=1.3.0  # Machine learning
matplotlib>=3.7.0    # VisualizaÃ§Ã£o
seaborn>=0.12.0      # GrÃ¡ficos estatÃ­sticos
numpy>=1.24.0        # OperaÃ§Ãµes numÃ©ricas
```

Instalar todas:
```bash
pip install librosa scikit-learn matplotlib seaborn numpy
```

---

## ğŸ’¡ Dicas para ApresentaÃ§Ã£o

### Pontos Principais:

1. **Problema:** Como computadores podem identificar emoÃ§Ãµes humanas?

2. **SoluÃ§Ã£o:** Machine learning + anÃ¡lise acÃºstica

3. **Como funciona:**
   - ExtraÃ­mos caracterÃ­sticas sonoras (MFCCs, pitch, energia...)
   - Treinamos um modelo para reconhecer padrÃµes
   - Modelo aprende que raiva = pitch alto + energia alta, etc.

4. **AplicaÃ§Ãµes:**
   - Call centers (detectar clientes insatisfeitos)
   - SaÃºde mental (monitorar estado emocional)
   - Games e entretenimento
   - Assistentes virtuais mais empÃ¡ticos

### Estrutura Sugerida:

1. IntroduÃ§Ã£o (2 min)
2. Como emoÃ§Ãµes afetam a voz (3 min)
3. Features extraÃ­das (5 min)
4. Pipeline e modelo (5 min)
5. Resultados e visualizaÃ§Ãµes (3 min)
6. Demo ao vivo (2 min) â† Use o notebook!
7. ConclusÃ£o e perguntas (5 min)

---

## ğŸš€ Melhorias PossÃ­veis

Para expandir o projeto:

### NÃ­vel IntermediÃ¡rio:
- âœ… Adicionar mais emoÃ§Ãµes (surpresa, medo, nojo)
- âœ… Data augmentation (pitch shift, time stretch)
- âœ… Grid search para otimizar hiperparÃ¢metros

### NÃ­vel AvanÃ§ado:
- ğŸ§  Deep Learning com CNNs (processar espectrogramas)
- ğŸ”„ RNNs/LSTMs (capturar dependÃªncias temporais)
- ğŸ¯ Transfer learning (usar modelos prÃ©-treinados)
- ğŸ“± Deploy como API REST ou app mobile

---

## ğŸ› Troubleshooting

### Erro: "No module named 'librosa'"
```bash
pip install librosa
```

### Erro ao carregar Ã¡udio
- Certifique-se que o arquivo Ã© .wav ou .mp3
- Taxa de amostragem recomendada: 16kHz ou 22kHz
- Ãudio mono (1 canal)

### AcurÃ¡cia muito baixa
- Verifique se os dados estÃ£o balanceados
- Tente aumentar o nÃºmero de amostras
- Experimente outros modelos (RF vs SVM)
- Normalize os dados

---

## ğŸ“ Suporte

Para dÃºvidas sobre o cÃ³digo ou implementaÃ§Ã£o:
- Consulte o notebook interativo
- Leia os comentÃ¡rios no cÃ³digo
- Experimente com os exemplos fornecidos

---

## âœ… Checklist para ApresentaÃ§Ã£o

- [ ] Testei o cÃ³digo localmente
- [ ] Entendo o que cada feature representa
- [ ] Posso explicar o pipeline completo
- [ ] Preparei exemplos de Ã¡udio para demo
- [ ] Revisei os resultados e mÃ©tricas
- [ ] Preparei respostas para perguntas comuns

---

## ğŸ“ Conceitos-Chave para Explicar

### MFCCs
"Coeficientes que capturam a forma do envelope espectral da voz, similar a como nosso ouvido processa som"

### SVM
"Algoritmo que encontra o melhor hiperplano para separar as classes no espaÃ§o de features"

### Spectral Contrast
"Mede a diferenÃ§a entre picos e vales no espectro de frequÃªncias"

### Zero Crossing Rate
"Quantas vezes o sinal de Ã¡udio cruza o eixo zero - alto em sons sibilantes"

---

## ğŸ“„ LicenÃ§a

Este cÃ³digo Ã© fornecido como material educacional.
Sinta-se livre para usar, modificar e compartilhar.

---

**Boa sorte na sua apresentaÃ§Ã£o! ğŸ‰**
"# ravdess-ml-example" 
